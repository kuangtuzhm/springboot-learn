2018-08-07 14:15:08,130 [main] INFO  com.zealot.StartUp - Starting StartUp on 123-PC with PID 20128 (E:\works\springboot-learn\springboot-learn-kafkaconsumer\target\classes started by 123 in E:\works\springboot-learn\springboot-learn-kafkaconsumer)
2018-08-07 14:15:08,132 [main] INFO  com.zealot.StartUp - The following profiles are active: dev
2018-08-07 14:15:08,186 [main] INFO  o.s.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@68999068: startup date [Tue Aug 07 14:15:08 CST 2018]; root of context hierarchy
2018-08-07 14:15:08,937 [main] ERROR org.springframework.boot.SpringApplication - Application run failed
java.lang.IllegalStateException: Error processing condition on org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration.kafkaConsumerFactory
	at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:64)
	at org.springframework.context.annotation.ConditionEvaluator.shouldSkip(ConditionEvaluator.java:108)
	at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForBeanMethod(ConfigurationClassBeanDefinitionReader.java:180)
	at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:141)
	at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:117)
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:328)
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:233)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:273)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:93)
	at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:694)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:532)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:140)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:759)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:395)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:327)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1255)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1243)
	at com.zealot.StartUp.main(StartUp.java:15)
Caused by: java.lang.IllegalStateException: Failed to introspect Class [org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration] from ClassLoader [sun.misc.Launcher$AppClassLoader@2a139a55]
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:659)
	at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:556)
	at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:541)
	at org.springframework.util.ReflectionUtils.getUniqueDeclaredMethods(ReflectionUtils.java:599)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryMethod(AbstractAutowireCapableBeanFactory.java:726)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineTargetType(AbstractAutowireCapableBeanFactory.java:667)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.predictBeanType(AbstractAutowireCapableBeanFactory.java:635)
	at org.springframework.beans.factory.support.AbstractBeanFactory.isFactoryBean(AbstractBeanFactory.java:1489)
	at org.springframework.beans.factory.support.AbstractBeanFactory.isFactoryBean(AbstractBeanFactory.java:1012)
	at org.springframework.boot.autoconfigure.condition.BeanTypeRegistry.addBeanTypeForNonAliasDefinition(BeanTypeRegistry.java:164)
	at org.springframework.boot.autoconfigure.condition.BeanTypeRegistry.addBeanType(BeanTypeRegistry.java:153)
	at org.springframework.boot.autoconfigure.condition.BeanTypeRegistry.updateTypesIfNecessary(BeanTypeRegistry.java:203)
	at org.springframework.boot.autoconfigure.condition.BeanTypeRegistry.getNamesForType(BeanTypeRegistry.java:115)
	at org.springframework.boot.autoconfigure.condition.OnBeanCondition.collectBeanNamesForType(OnBeanCondition.java:265)
	at org.springframework.boot.autoconfigure.condition.OnBeanCondition.getBeanNamesForType(OnBeanCondition.java:254)
	at org.springframework.boot.autoconfigure.condition.OnBeanCondition.getMatchingBeans(OnBeanCondition.java:196)
	at org.springframework.boot.autoconfigure.condition.OnBeanCondition.getMatchOutcome(OnBeanCondition.java:116)
	at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:47)
	... 17 common frames omitted
Caused by: java.lang.NoClassDefFoundError: org/springframework/kafka/core/KafkaAdmin
	at java.lang.Class.getDeclaredMethods0(Native Method)
	at java.lang.Class.privateGetDeclaredMethods(Unknown Source)
	at java.lang.Class.getDeclaredMethods(Unknown Source)
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:641)
	... 34 common frames omitted
Caused by: java.lang.ClassNotFoundException: org.springframework.kafka.core.KafkaAdmin
	at java.net.URLClassLoader.findClass(Unknown Source)
	at java.lang.ClassLoader.loadClass(Unknown Source)
	at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)
	at java.lang.ClassLoader.loadClass(Unknown Source)
	... 38 common frames omitted
2018-08-07 14:15:08,940 [main] INFO  o.s.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext - Closing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@68999068: startup date [Tue Aug 07 14:15:08 CST 2018]; root of context hierarchy
2018-08-07 14:15:08,942 [main] WARN  org.springframework.boot.SpringApplication - Unable to close ApplicationContext
java.lang.IllegalStateException: Failed to introspect Class [org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration] from ClassLoader [sun.misc.Launcher$AppClassLoader@2a139a55]
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:659)
	at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:556)
	at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:541)
	at org.springframework.util.ReflectionUtils.getUniqueDeclaredMethods(ReflectionUtils.java:599)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryMethod(AbstractAutowireCapableBeanFactory.java:726)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineTargetType(AbstractAutowireCapableBeanFactory.java:667)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.predictBeanType(AbstractAutowireCapableBeanFactory.java:635)
	at org.springframework.beans.factory.support.AbstractBeanFactory.isFactoryBean(AbstractBeanFactory.java:1489)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doGetBeanNamesForType(DefaultListableBeanFactory.java:420)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:390)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:511)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:503)
	at org.springframework.context.support.AbstractApplicationContext.getBeansOfType(AbstractApplicationContext.java:1198)
	at org.springframework.boot.SpringApplication.getExitCodeFromMappedException(SpringApplication.java:889)
	at org.springframework.boot.SpringApplication.getExitCodeFromException(SpringApplication.java:875)
	at org.springframework.boot.SpringApplication.handleExitCode(SpringApplication.java:861)
	at org.springframework.boot.SpringApplication.handleRunFailure(SpringApplication.java:810)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:338)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1255)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1243)
	at com.zealot.StartUp.main(StartUp.java:15)
Caused by: java.lang.NoClassDefFoundError: org/springframework/kafka/core/KafkaAdmin
	at java.lang.Class.getDeclaredMethods0(Native Method)
	at java.lang.Class.privateGetDeclaredMethods(Unknown Source)
	at java.lang.Class.getDeclaredMethods(Unknown Source)
	at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:641)
	... 20 common frames omitted
Caused by: java.lang.ClassNotFoundException: org.springframework.kafka.core.KafkaAdmin
	at java.net.URLClassLoader.findClass(Unknown Source)
	at java.lang.ClassLoader.loadClass(Unknown Source)
	at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)
	at java.lang.ClassLoader.loadClass(Unknown Source)
	... 24 common frames omitted
2018-08-07 14:23:36,302 [main] INFO  com.zealot.StartUp - Starting StartUp on 123-PC with PID 26196 (E:\works\springboot-learn\springboot-learn-kafkaconsumer\target\classes started by 123 in E:\works\springboot-learn\springboot-learn-kafkaconsumer)
2018-08-07 14:23:36,304 [main] INFO  com.zealot.StartUp - The following profiles are active: dev
2018-08-07 14:23:36,361 [main] INFO  o.s.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@20deea7f: startup date [Tue Aug 07 14:23:36 CST 2018]; root of context hierarchy
2018-08-07 14:23:37,142 [main] INFO  o.s.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$af042b25] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-08-07 14:23:38,256 [main] INFO  org.springframework.boot.web.embedded.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9659 (http)
2018-08-07 14:23:38,273 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9659"]
2018-08-07 14:23:38,288 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2018-08-07 14:23:38,288 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.31
2018-08-07 14:23:38,300 [localhost-startStop-1] INFO  org.apache.catalina.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [C:\Program Files\Java\jre1.8.0_144\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\TortoiseSVN\bin;D:\worksoft\apache-maven-3.3.1\bin;C:\Program Files\Java\jdk1.7.0_75\bin;C:\Program Files\Java\jdk1.7.0_75\jre\bin;C:\Go\bin;C:\Program Files\Git\bin;D:\worksoft\hadoop-2.7.6\bin;D:\worksoft\SSH;.]
2018-08-07 14:23:38,458 [localhost-startStop-1] INFO  org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2018-08-07 14:23:38,458 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2098 ms
2018-08-07 14:23:38,775 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
2018-08-07 14:23:38,780 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
2018-08-07 14:23:38,781 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-08-07 14:23:38,781 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-08-07 14:23:38,781 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
2018-08-07 14:23:38,968 [main] INFO  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-08-07 14:23:39,194 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@20deea7f: startup date [Tue Aug 07 14:23:36 CST 2018]; root of context hierarchy
2018-08-07 14:23:39,267 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/kafka/send],methods=[GET]}" onto public java.lang.String com.zealot.learn.kafka.controller.CollectController.sendKafka(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-08-07 14:23:39,269 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-08-07 14:23:39,269 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-08-07 14:23:39,299 [main] INFO  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-08-07 14:23:39,299 [main] INFO  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-08-07 14:23:39,868 [main] INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2018-08-07 14:23:39,875 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 2147483547
2018-08-07 14:23:39,902 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:23:39,995 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:23:39,995 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:23:40,001 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:23:40,008 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:23:40,022 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:23:40,023 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:23:40,023 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:23:40,024 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:23:40,040 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:23:40,040 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:23:40,040 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:23:40,042 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:23:40,055 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:23:40,055 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:23:40,055 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:23:40,056 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:23:40,076 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:23:40,076 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:23:40,077 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:23:40,078 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:23:40,092 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:23:40,092 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:23:40,093 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:23:40,094 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:23:40,106 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:23:40,106 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:23:40,106 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:23:40,107 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:23:40,120 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:23:40,120 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:23:40,120 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:23:40,121 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:23:40,136 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:23:40,136 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:23:40,137 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:23:40,141 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:23:40,156 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:23:40,156 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:23:40,158 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:23:40,177 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9659"]
2018-08-07 14:23:40,190 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
2018-08-07 14:23:40,200 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:23:40,200 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:23:40,201 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:23:40,200 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:23:40,196 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:23:40,196 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:23:40,199 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:23:40,208 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:23:40,196 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:23:40,199 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:23:40,225 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:23:40,225 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:23:40,227 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:23:40,228 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:23:40,228 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:23:40,228 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:23:40,228 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:23:40,228 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] (Re-)joining group
2018-08-07 14:23:40,231 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:23:40,231 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:23:40,231 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:23:40,231 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:23:40,233 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:23:40,233 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] (Re-)joining group
2018-08-07 14:23:40,225 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:23:40,233 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] (Re-)joining group
2018-08-07 14:23:40,227 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:23:40,233 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:23:40,233 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] (Re-)joining group
2018-08-07 14:23:40,228 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] (Re-)joining group
2018-08-07 14:23:40,228 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:23:40,234 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] (Re-)joining group
2018-08-07 14:23:40,231 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:23:40,234 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:23:40,234 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] (Re-)joining group
2018-08-07 14:23:40,232 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:23:40,235 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] (Re-)joining group
2018-08-07 14:23:40,231 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] (Re-)joining group
2018-08-07 14:23:40,233 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:23:40,236 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] (Re-)joining group
2018-08-07 14:23:40,253 [main] INFO  org.springframework.boot.web.embedded.tomcat.TomcatWebServer - Tomcat started on port(s): 9659 (http) with context path ''
2018-08-07 14:23:40,257 [main] INFO  com.zealot.StartUp - Started StartUp in 4.422 seconds (JVM running for 4.891)
2018-08-07 14:23:40,508 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Successfully joined group with generation 4
2018-08-07 14:23:40,509 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Successfully joined group with generation 4
2018-08-07 14:23:40,510 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Successfully joined group with generation 4
2018-08-07 14:23:40,510 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:23:40,510 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:23:40,509 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Successfully joined group with generation 4
2018-08-07 14:23:40,510 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:23:40,511 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:23:40,511 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:23:40,511 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:23:40,512 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Successfully joined group with generation 4
2018-08-07 14:23:40,511 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Successfully joined group with generation 4
2018-08-07 14:23:40,513 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:23:40,512 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Successfully joined group with generation 4
2018-08-07 14:23:40,513 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:23:40,513 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:23:40,513 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:23:40,513 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:23:40,513 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:23:40,514 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Setting newly assigned partitions [flume.log.test-3]
2018-08-07 14:23:40,517 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Successfully joined group with generation 4
2018-08-07 14:23:40,518 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Setting newly assigned partitions [flume.log.test-4]
2018-08-07 14:23:40,518 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Successfully joined group with generation 4
2018-08-07 14:23:40,518 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Setting newly assigned partitions [flume.log.test-0]
2018-08-07 14:23:40,518 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Successfully joined group with generation 4
2018-08-07 14:23:40,520 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:23:40,520 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:23:40,522 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [flume.log.test-0]
2018-08-07 14:23:40,522 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [flume.log.test-3]
2018-08-07 14:23:40,528 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [flume.log.test-4]
2018-08-07 14:23:54,820 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 2
2018-08-07 14:23:54,820 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 5
2018-08-07 14:23:54,820 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=2
2018-08-07 14:23:54,820 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 1
2018-08-07 14:23:54,820 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 3
2018-08-07 14:23:54,820 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=1
2018-08-07 14:23:54,820 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=3
2018-08-07 14:23:54,820 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=5
2018-08-07 14:23:54,822 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 4
2018-08-07 14:23:54,823 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=4
2018-08-07 14:23:54,823 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 6
2018-08-07 14:23:54,823 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=6
2018-08-07 14:23:54,823 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 9
2018-08-07 14:23:54,823 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=9
2018-08-07 14:23:54,824 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 7
2018-08-07 14:23:54,824 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=7
2018-08-07 14:24:29,236 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 2
2018-08-07 14:24:29,236 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=2
2018-08-07 14:24:29,238 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 1
2018-08-07 14:24:29,238 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=1
2018-08-07 14:24:29,239 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 3
2018-08-07 14:24:29,239 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=3
2018-08-07 14:24:29,239 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 4
2018-08-07 14:24:29,239 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=4
2018-08-07 14:24:29,241 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 5
2018-08-07 14:24:29,241 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=5
2018-08-07 14:24:29,243 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 7
2018-08-07 14:24:29,244 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=7
2018-08-07 14:24:29,245 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 6
2018-08-07 14:24:29,246 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=6
2018-08-07 14:24:29,249 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 9
2018-08-07 14:24:29,249 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=9
2018-08-07 14:25:01,712 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 1
2018-08-07 14:25:01,712 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=1
2018-08-07 14:25:01,715 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 5
2018-08-07 14:25:01,715 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 2
2018-08-07 14:25:01,715 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=5
2018-08-07 14:25:01,715 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=2
2018-08-07 14:25:01,715 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 3
2018-08-07 14:25:01,715 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=3
2018-08-07 14:25:01,716 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 4
2018-08-07 14:25:01,716 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=4
2018-08-07 14:25:01,716 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 6
2018-08-07 14:25:01,716 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=6
2018-08-07 14:25:01,718 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 7
2018-08-07 14:25:01,719 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=7
2018-08-07 14:25:01,720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 9
2018-08-07 14:25:01,720 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=9
2018-08-07 14:25:58,307 [main] INFO  com.zealot.StartUp - Starting StartUp on 123-PC with PID 23460 (E:\works\springboot-learn\springboot-learn-kafkaconsumer\target\classes started by 123 in E:\works\springboot-learn\springboot-learn-kafkaconsumer)
2018-08-07 14:25:58,316 [main] INFO  com.zealot.StartUp - The following profiles are active: dev
2018-08-07 14:25:58,375 [main] INFO  o.s.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@72ade7e3: startup date [Tue Aug 07 14:25:58 CST 2018]; root of context hierarchy
2018-08-07 14:25:59,303 [main] INFO  o.s.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$a6ac6853] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-08-07 14:26:00,350 [main] INFO  org.springframework.boot.web.embedded.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9659 (http)
2018-08-07 14:26:00,366 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9659"]
2018-08-07 14:26:00,378 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2018-08-07 14:26:00,378 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.31
2018-08-07 14:26:00,389 [localhost-startStop-1] INFO  org.apache.catalina.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [C:\Program Files\Java\jre1.8.0_144\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\TortoiseSVN\bin;D:\worksoft\apache-maven-3.3.1\bin;C:\Program Files\Java\jdk1.7.0_75\bin;C:\Program Files\Java\jdk1.7.0_75\jre\bin;C:\Go\bin;C:\Program Files\Git\bin;D:\worksoft\hadoop-2.7.6\bin;D:\worksoft\SSH;.]
2018-08-07 14:26:00,598 [localhost-startStop-1] INFO  org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2018-08-07 14:26:00,599 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2224 ms
2018-08-07 14:26:00,857 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
2018-08-07 14:26:00,863 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
2018-08-07 14:26:00,863 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-08-07 14:26:00,863 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-08-07 14:26:00,864 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
2018-08-07 14:26:01,111 [main] INFO  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-08-07 14:26:01,431 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@72ade7e3: startup date [Tue Aug 07 14:25:58 CST 2018]; root of context hierarchy
2018-08-07 14:26:01,550 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/kafka/send],methods=[GET]}" onto public java.lang.String com.zealot.learn.kafka.controller.CollectController.sendKafka(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-08-07 14:26:01,554 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-08-07 14:26:01,555 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-08-07 14:26:01,603 [main] INFO  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-08-07 14:26:01,604 [main] INFO  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-08-07 14:26:02,027 [main] INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2018-08-07 14:26:02,036 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 2147483547
2018-08-07 14:26:02,069 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:26:02,178 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:26:02,178 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:26:02,184 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:26:02,192 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:26:02,208 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:26:02,208 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:26:02,209 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:26:02,210 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:26:02,226 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:26:02,226 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:26:02,226 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:26:02,229 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:26:02,246 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:26:02,246 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:26:02,247 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:26:02,248 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:26:02,264 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:26:02,264 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:26:02,264 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:26:02,265 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:26:02,282 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:26:02,282 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:26:02,282 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:26:02,283 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:26:02,306 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:26:02,306 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:26:02,307 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:26:02,308 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:26:02,329 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:26:02,329 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:26:02,329 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:26:02,330 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:26:02,346 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:26:02,347 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:26:02,347 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:26:02,349 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:26:02,365 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:26:02,365 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:26:02,366 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:26:02,386 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9659"]
2018-08-07 14:26:02,401 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
2018-08-07 14:26:02,430 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:26:02,430 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:26:02,430 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:26:02,432 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:26:02,431 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:26:02,431 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:26:02,439 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:26:02,432 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:26:02,447 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:26:02,453 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:26:02,454 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:26:02,454 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:26:02,456 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:26:02,455 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:26:02,456 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:26:02,455 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:26:02,456 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] (Re-)joining group
2018-08-07 14:26:02,456 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:26:02,456 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] (Re-)joining group
2018-08-07 14:26:02,456 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] (Re-)joining group
2018-08-07 14:26:02,456 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:26:02,455 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:26:02,457 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] (Re-)joining group
2018-08-07 14:26:02,457 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:26:02,457 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:26:02,455 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:26:02,457 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:26:02,457 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] (Re-)joining group
2018-08-07 14:26:02,457 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:26:02,457 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:26:02,458 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:26:02,457 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] (Re-)joining group
2018-08-07 14:26:02,458 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] (Re-)joining group
2018-08-07 14:26:02,458 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] (Re-)joining group
2018-08-07 14:26:02,455 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:26:02,458 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:26:02,458 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] (Re-)joining group
2018-08-07 14:26:02,460 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:26:02,461 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:26:02,461 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] (Re-)joining group
2018-08-07 14:26:02,485 [main] INFO  org.springframework.boot.web.embedded.tomcat.TomcatWebServer - Tomcat started on port(s): 9659 (http) with context path ''
2018-08-07 14:26:02,490 [main] INFO  com.zealot.StartUp - Started StartUp in 4.713 seconds (JVM running for 5.41)
2018-08-07 14:26:04,677 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Successfully joined group with generation 6
2018-08-07 14:26:04,679 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Successfully joined group with generation 6
2018-08-07 14:26:04,680 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Successfully joined group with generation 6
2018-08-07 14:26:04,680 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Successfully joined group with generation 6
2018-08-07 14:26:04,681 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Successfully joined group with generation 6
2018-08-07 14:26:04,681 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:26:04,678 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Successfully joined group with generation 6
2018-08-07 14:26:04,681 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Successfully joined group with generation 6
2018-08-07 14:26:04,681 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:26:04,681 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:26:04,682 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:26:04,682 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Setting newly assigned partitions [flume.log.test-4]
2018-08-07 14:26:04,683 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Setting newly assigned partitions [flume.log.test-3]
2018-08-07 14:26:04,678 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Successfully joined group with generation 6
2018-08-07 14:26:04,677 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Successfully joined group with generation 6
2018-08-07 14:26:04,688 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:26:04,688 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Successfully joined group with generation 6
2018-08-07 14:26:04,688 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:26:04,689 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:26:04,689 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:26:04,690 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [flume.log.test-3]
2018-08-07 14:26:04,681 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:26:04,693 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:26:04,681 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:26:04,682 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:26:04,693 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:26:04,688 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:26:04,689 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Setting newly assigned partitions [flume.log.test-1]
2018-08-07 14:26:04,695 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [flume.log.test-4]
2018-08-07 14:26:04,700 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [flume.log.test-1]
2018-08-07 14:26:32,379 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 1
2018-08-07 14:26:32,379 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=1
2018-08-07 14:26:32,379 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 0
2018-08-07 14:26:32,379 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 2
2018-08-07 14:26:32,380 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=0
2018-08-07 14:26:32,380 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=2
2018-08-07 14:26:32,380 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 3
2018-08-07 14:26:32,380 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=3
2018-08-07 14:26:32,380 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 4
2018-08-07 14:26:32,380 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=4
2018-08-07 14:26:32,383 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 7
2018-08-07 14:26:32,383 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=7
2018-08-07 14:26:32,383 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 6
2018-08-07 14:26:32,384 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=6
2018-08-07 14:26:32,384 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 9
2018-08-07 14:26:32,384 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=9
2018-08-07 14:26:58,171 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 1
2018-08-07 14:26:58,171 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=1
2018-08-07 14:26:58,606 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 2
2018-08-07 14:26:58,606 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=2
2018-08-07 14:26:58,608 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 0
2018-08-07 14:26:58,609 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 7
2018-08-07 14:26:58,609 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=7
2018-08-07 14:26:58,610 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 3
2018-08-07 14:26:58,611 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=3
2018-08-07 14:26:58,611 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 4
2018-08-07 14:26:58,611 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=4
2018-08-07 14:26:58,609 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=0
2018-08-07 14:26:58,611 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 6
2018-08-07 14:26:58,612 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=6
2018-08-07 14:26:58,613 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 9
2018-08-07 14:26:58,614 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=9
2018-08-07 14:27:34,502 [main] INFO  com.zealot.StartUp - Starting StartUp on 123-PC with PID 23988 (E:\works\springboot-learn\springboot-learn-kafkaconsumer\target\classes started by 123 in E:\works\springboot-learn\springboot-learn-kafkaconsumer)
2018-08-07 14:27:34,511 [main] INFO  com.zealot.StartUp - The following profiles are active: dev
2018-08-07 14:27:34,566 [main] INFO  o.s.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@38aa816f: startup date [Tue Aug 07 14:27:34 CST 2018]; root of context hierarchy
2018-08-07 14:27:35,443 [main] INFO  o.s.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$77cd5a10] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-08-07 14:27:36,438 [main] INFO  org.springframework.boot.web.embedded.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9659 (http)
2018-08-07 14:27:36,455 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9659"]
2018-08-07 14:27:36,467 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2018-08-07 14:27:36,468 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.31
2018-08-07 14:27:36,480 [localhost-startStop-1] INFO  org.apache.catalina.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [C:\Program Files\Java\jre1.8.0_144\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\TortoiseSVN\bin;D:\worksoft\apache-maven-3.3.1\bin;C:\Program Files\Java\jdk1.7.0_75\bin;C:\Program Files\Java\jdk1.7.0_75\jre\bin;C:\Go\bin;C:\Program Files\Git\bin;D:\worksoft\hadoop-2.7.6\bin;D:\worksoft\SSH;.]
2018-08-07 14:27:36,640 [localhost-startStop-1] INFO  org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2018-08-07 14:27:36,640 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2074 ms
2018-08-07 14:27:36,875 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
2018-08-07 14:27:36,881 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
2018-08-07 14:27:36,881 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-08-07 14:27:36,882 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-08-07 14:27:36,882 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
2018-08-07 14:27:37,128 [main] INFO  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-08-07 14:27:37,400 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@38aa816f: startup date [Tue Aug 07 14:27:34 CST 2018]; root of context hierarchy
2018-08-07 14:27:37,496 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/kafka/send],methods=[GET]}" onto public java.lang.String com.zealot.learn.kafka.controller.CollectController.sendKafka(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-08-07 14:27:37,499 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-08-07 14:27:37,499 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-08-07 14:27:37,548 [main] INFO  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-08-07 14:27:37,548 [main] INFO  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-08-07 14:27:38,010 [main] INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2018-08-07 14:27:38,029 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 2147483547
2018-08-07 14:27:38,073 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:27:38,192 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:27:38,192 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:27:38,200 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:27:38,210 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:27:38,225 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:27:38,226 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:27:38,227 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:27:38,228 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:27:38,246 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:27:38,246 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:27:38,247 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:27:38,248 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:27:38,265 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:27:38,266 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:27:38,266 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:27:38,267 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:27:38,282 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:27:38,282 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:27:38,283 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:27:38,284 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:27:38,298 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:27:38,299 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:27:38,299 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:27:38,300 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:27:38,317 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:27:38,317 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:27:38,317 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:27:38,318 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:27:38,335 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:27:38,335 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:27:38,335 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:27:38,336 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:27:38,351 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:27:38,351 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:27:38,351 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:27:38,352 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 14:27:38,394 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 14:27:38,394 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 14:27:38,410 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 14:27:38,430 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9659"]
2018-08-07 14:27:38,449 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
2018-08-07 14:27:38,476 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:27:38,478 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:27:38,476 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:27:38,477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:27:38,478 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:27:38,476 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:27:38,477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:27:38,486 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:27:38,477 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:27:38,487 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 14:27:38,492 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:27:38,497 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:27:38,498 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:27:38,492 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:27:38,498 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:27:38,492 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:27:38,493 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:27:38,493 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:27:38,499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:27:38,499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:27:38,498 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:27:38,498 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:27:38,498 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:27:38,498 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 14:27:38,498 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:27:38,498 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:27:38,499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] (Re-)joining group
2018-08-07 14:27:38,499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:27:38,499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] (Re-)joining group
2018-08-07 14:27:38,499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] (Re-)joining group
2018-08-07 14:27:38,499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:27:38,499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:27:38,499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] (Re-)joining group
2018-08-07 14:27:38,499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] (Re-)joining group
2018-08-07 14:27:38,500 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] (Re-)joining group
2018-08-07 14:27:38,499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 14:27:38,499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] (Re-)joining group
2018-08-07 14:27:38,500 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] (Re-)joining group
2018-08-07 14:27:38,499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] (Re-)joining group
2018-08-07 14:27:38,499 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] (Re-)joining group
2018-08-07 14:27:38,506 [main] INFO  org.springframework.boot.web.embedded.tomcat.TomcatWebServer - Tomcat started on port(s): 9659 (http) with context path ''
2018-08-07 14:27:38,511 [main] INFO  com.zealot.StartUp - Started StartUp in 4.551 seconds (JVM running for 5.199)
2018-08-07 14:27:40,744 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Successfully joined group with generation 8
2018-08-07 14:27:40,744 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Successfully joined group with generation 8
2018-08-07 14:27:40,745 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Successfully joined group with generation 8
2018-08-07 14:27:40,746 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Successfully joined group with generation 8
2018-08-07 14:27:40,745 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Successfully joined group with generation 8
2018-08-07 14:27:40,757 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Successfully joined group with generation 8
2018-08-07 14:27:40,756 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Successfully joined group with generation 8
2018-08-07 14:27:40,764 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Successfully joined group with generation 8
2018-08-07 14:27:40,765 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Successfully joined group with generation 8
2018-08-07 14:27:40,766 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Successfully joined group with generation 8
2018-08-07 14:27:40,768 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:27:40,769 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:27:40,769 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:27:40,769 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:27:40,770 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Setting newly assigned partitions [flume.log.test-1]
2018-08-07 14:27:40,770 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:27:40,768 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:27:40,770 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Setting newly assigned partitions [flume.log.test-4]
2018-08-07 14:27:40,770 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:27:40,770 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Setting newly assigned partitions [flume.log.test-2]
2018-08-07 14:27:40,769 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:27:40,770 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:27:40,770 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:27:40,771 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:27:40,768 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 14:27:40,771 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:27:40,770 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 14:27:40,777 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [flume.log.test-2]
2018-08-07 14:27:40,782 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [flume.log.test-4]
2018-08-07 14:27:40,785 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [flume.log.test-1]
2018-08-07 14:27:56,000 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 8
2018-08-07 14:27:56,000 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 0
2018-08-07 14:27:56,001 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=8
2018-08-07 14:27:56,001 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=0
2018-08-07 14:27:56,003 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 1
2018-08-07 14:27:56,004 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=1
2018-08-07 14:27:56,006 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 7
2018-08-07 14:27:56,007 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=7
2018-08-07 15:23:34,047 [main] INFO  com.zealot.StartUp - Starting StartUp on 123-PC with PID 16640 (E:\works\springboot-learn\springboot-learn-kafkaconsumer\target\classes started by 123 in E:\works\springboot-learn\springboot-learn-kafkaconsumer)
2018-08-07 15:23:34,058 [main] INFO  com.zealot.StartUp - The following profiles are active: dev
2018-08-07 15:23:34,116 [main] INFO  o.s.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@2bec854f: startup date [Tue Aug 07 15:23:34 CST 2018]; root of context hierarchy
2018-08-07 15:23:35,000 [main] INFO  o.s.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$17457ff9] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-08-07 15:23:36,038 [main] INFO  org.springframework.boot.web.embedded.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9659 (http)
2018-08-07 15:23:36,054 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9659"]
2018-08-07 15:23:36,068 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2018-08-07 15:23:36,068 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.31
2018-08-07 15:23:36,081 [localhost-startStop-1] INFO  org.apache.catalina.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [C:\Program Files\Java\jre1.8.0_144\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\TortoiseSVN\bin;D:\worksoft\apache-maven-3.3.1\bin;C:\Program Files\Java\jdk1.7.0_75\bin;C:\Program Files\Java\jdk1.7.0_75\jre\bin;C:\Go\bin;C:\Program Files\Git\bin;D:\worksoft\hadoop-2.7.6\bin;D:\worksoft\SSH;.]
2018-08-07 15:23:36,263 [localhost-startStop-1] INFO  org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2018-08-07 15:23:36,264 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2148 ms
2018-08-07 15:23:36,504 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
2018-08-07 15:23:36,510 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
2018-08-07 15:23:36,511 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-08-07 15:23:36,511 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-08-07 15:23:36,511 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
2018-08-07 15:23:36,750 [main] INFO  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-08-07 15:23:37,035 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@2bec854f: startup date [Tue Aug 07 15:23:34 CST 2018]; root of context hierarchy
2018-08-07 15:23:37,128 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/kafka/send],methods=[GET]}" onto public java.lang.String com.zealot.learn.kafka.controller.CollectController.sendKafka(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-08-07 15:23:37,132 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-08-07 15:23:37,132 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-08-07 15:23:37,171 [main] INFO  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-08-07 15:23:37,172 [main] INFO  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-08-07 15:23:37,552 [main] INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2018-08-07 15:23:37,561 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 2147483547
2018-08-07 15:23:37,588 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:23:37,684 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:23:37,684 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:23:37,692 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:23:37,701 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:23:37,717 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:23:37,717 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:23:37,718 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:23:37,719 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:23:37,742 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:23:37,746 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:23:37,747 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:23:37,748 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:23:37,778 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:23:37,778 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:23:37,779 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:23:37,780 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:23:37,810 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:23:37,810 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:23:37,810 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:23:37,821 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:23:37,847 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:23:37,847 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:23:37,847 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:23:37,848 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:23:37,873 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:23:37,873 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:23:37,874 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:23:37,875 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:23:37,896 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:23:37,900 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:23:37,900 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:23:37,900 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:23:37,897 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:23:37,903 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:23:37,905 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:23:37,906 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:23:37,907 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:23:37,911 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:23:37,911 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:23:37,916 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:23:37,916 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:23:37,916 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:23:37,918 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:23:37,919 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:23:37,919 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:23:37,916 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:23:37,920 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] (Re-)joining group
2018-08-07 15:23:37,920 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:23:37,921 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] (Re-)joining group
2018-08-07 15:23:37,916 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:23:37,921 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:23:37,921 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] (Re-)joining group
2018-08-07 15:23:37,918 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:23:37,921 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:23:37,921 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] (Re-)joining group
2018-08-07 15:23:37,918 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:23:37,921 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] (Re-)joining group
2018-08-07 15:23:37,918 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:23:37,921 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] (Re-)joining group
2018-08-07 15:23:37,920 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] (Re-)joining group
2018-08-07 15:23:37,936 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:23:37,940 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:23:37,940 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:23:37,940 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] (Re-)joining group
2018-08-07 15:23:37,942 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:23:37,942 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:23:37,942 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:23:37,943 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:23:37,973 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:23:37,973 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:23:37,973 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:23:37,980 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:23:37,985 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:23:37,986 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:23:37,987 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] (Re-)joining group
2018-08-07 15:23:37,993 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9659"]
2018-08-07 15:23:37,993 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:23:37,997 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:23:37,997 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:23:37,998 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] (Re-)joining group
2018-08-07 15:23:38,019 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
2018-08-07 15:23:38,105 [main] INFO  org.springframework.boot.web.embedded.tomcat.TomcatWebServer - Tomcat started on port(s): 9659 (http) with context path ''
2018-08-07 15:23:38,111 [main] INFO  com.zealot.StartUp - Started StartUp in 4.591 seconds (JVM running for 5.331)
2018-08-07 15:23:40,841 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Successfully joined group with generation 10
2018-08-07 15:23:40,845 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Successfully joined group with generation 10
2018-08-07 15:23:40,845 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Successfully joined group with generation 10
2018-08-07 15:23:40,845 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Successfully joined group with generation 10
2018-08-07 15:23:40,849 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Successfully joined group with generation 10
2018-08-07 15:23:40,849 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 15:23:40,849 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 15:23:40,849 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Successfully joined group with generation 10
2018-08-07 15:23:40,850 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Successfully joined group with generation 10
2018-08-07 15:23:40,850 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 15:23:40,851 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 15:23:40,851 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 15:23:40,852 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 15:23:40,852 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 15:23:40,852 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 15:23:40,852 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Successfully joined group with generation 10
2018-08-07 15:23:40,853 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 15:23:40,853 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 15:23:40,853 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Setting newly assigned partitions [flume.log.test-2]
2018-08-07 15:23:40,853 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Setting newly assigned partitions [flume.log.test-1]
2018-08-07 15:23:40,855 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Successfully joined group with generation 10
2018-08-07 15:23:40,855 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 15:23:40,855 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 15:23:40,856 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Successfully joined group with generation 10
2018-08-07 15:23:40,856 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 15:23:40,856 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 15:23:40,856 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 15:23:40,856 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 15:23:40,861 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [flume.log.test-1]
2018-08-07 15:23:40,861 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [flume.log.test-2]
2018-08-07 15:24:03,716 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 0
2018-08-07 15:24:03,716 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的key: 8
2018-08-07 15:24:03,717 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=0
2018-08-07 15:24:03,717 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  com.zealot.learn.kafka.listener.Listener - kafka的value: 测试消息key=8
2018-08-07 15:24:20,845 [main] INFO  com.zealot.StartUp - Starting StartUp on 123-PC with PID 15864 (E:\works\springboot-learn\springboot-learn-kafkaconsumer\target\classes started by 123 in E:\works\springboot-learn\springboot-learn-kafkaconsumer)
2018-08-07 15:24:20,855 [main] INFO  com.zealot.StartUp - The following profiles are active: dev
2018-08-07 15:24:20,911 [main] INFO  o.s.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext - Refreshing org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@6aa8e115: startup date [Tue Aug 07 15:24:20 CST 2018]; root of context hierarchy
2018-08-07 15:24:21,816 [main] INFO  o.s.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$44d9d892] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-08-07 15:24:22,932 [main] INFO  org.springframework.boot.web.embedded.tomcat.TomcatWebServer - Tomcat initialized with port(s): 9659 (http)
2018-08-07 15:24:22,948 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-9659"]
2018-08-07 15:24:22,962 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2018-08-07 15:24:22,963 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.31
2018-08-07 15:24:22,973 [localhost-startStop-1] INFO  org.apache.catalina.core.AprLifecycleListener - The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [C:\Program Files\Java\jre1.8.0_144\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\ProgramData\Oracle\Java\javapath;C:\Program Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\TortoiseSVN\bin;D:\worksoft\apache-maven-3.3.1\bin;C:\Program Files\Java\jdk1.7.0_75\bin;C:\Program Files\Java\jdk1.7.0_75\jre\bin;C:\Go\bin;C:\Program Files\Git\bin;D:\worksoft\hadoop-2.7.6\bin;D:\worksoft\SSH;.]
2018-08-07 15:24:23,143 [localhost-startStop-1] INFO  org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2018-08-07 15:24:23,144 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2233 ms
2018-08-07 15:24:23,357 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.ServletRegistrationBean - Servlet dispatcherServlet mapped to [/]
2018-08-07 15:24:23,363 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
2018-08-07 15:24:23,363 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-08-07 15:24:23,363 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-08-07 15:24:23,363 [localhost-startStop-1] INFO  org.springframework.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
2018-08-07 15:24:23,599 [main] INFO  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-08-07 15:24:23,883 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext@6aa8e115: startup date [Tue Aug 07 15:24:20 CST 2018]; root of context hierarchy
2018-08-07 15:24:23,978 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/kafka/send],methods=[GET]}" onto public java.lang.String com.zealot.learn.kafka.controller.CollectController.sendKafka(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-08-07 15:24:23,981 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-08-07 15:24:23,981 [main] INFO  o.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-08-07 15:24:24,016 [main] INFO  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-08-07 15:24:24,016 [main] INFO  org.springframework.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-08-07 15:24:24,444 [main] INFO  org.springframework.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2018-08-07 15:24:24,452 [main] INFO  org.springframework.context.support.DefaultLifecycleProcessor - Starting beans in phase 2147483547
2018-08-07 15:24:24,487 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:24:24,585 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:24:24,585 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:24:24,594 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:24:24,602 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:24:24,619 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:24:24,619 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:24:24,620 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:24:24,621 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:24:24,640 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:24:24,640 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:24:24,640 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:24:24,641 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:24:24,664 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:24:24,665 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:24:24,665 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:24:24,666 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:24:24,686 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:24:24,686 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:24:24,686 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:24:24,687 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:24:24,708 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:24:24,708 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:24:24,709 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:24:24,711 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:24:24,731 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:24:24,732 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:24:24,732 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:24:24,734 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:24:24,756 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:24:24,756 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:24:24,757 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:24:24,758 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:24:24,771 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:24:24,771 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:24:24,771 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:24:24,772 [main] INFO  org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [172.16.10.113:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flumetest
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 6000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-08-07 15:24:24,791 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 1.0.1
2018-08-07 15:24:24,791 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : c0518aa65f25317e
2018-08-07 15:24:24,792 [main] INFO  org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService 
2018-08-07 15:24:24,812 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-9659"]
2018-08-07 15:24:24,832 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
2018-08-07 15:24:24,867 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:24:24,869 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:24:24,870 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:24:24,867 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:24:24,875 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:24:24,867 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:24:24,876 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:24:24,877 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:24:24,867 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:24:24,867 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Discovered group coordinator 172.16.10.113:9092 (id: 2147483647 rack: null)
2018-08-07 15:24:24,881 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:24:24,881 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:24:24,881 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:24:24,881 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] (Re-)joining group
2018-08-07 15:24:24,882 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:24:24,882 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:24:24,882 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] (Re-)joining group
2018-08-07 15:24:24,883 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:24:24,883 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:24:24,883 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] (Re-)joining group
2018-08-07 15:24:24,883 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:24:24,883 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:24:24,881 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:24:24,886 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] (Re-)joining group
2018-08-07 15:24:24,884 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:24:24,886 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:24:24,884 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:24:24,887 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:24:24,884 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:24:24,888 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] (Re-)joining group
2018-08-07 15:24:24,888 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Revoking previously assigned partitions []
2018-08-07 15:24:24,888 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:24:24,886 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:24:24,888 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] (Re-)joining group
2018-08-07 15:24:24,888 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] (Re-)joining group
2018-08-07 15:24:24,888 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:24:24,889 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] (Re-)joining group
2018-08-07 15:24:24,887 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
2018-08-07 15:24:24,891 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] (Re-)joining group
2018-08-07 15:24:24,887 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] (Re-)joining group
2018-08-07 15:24:24,903 [main] INFO  org.springframework.boot.web.embedded.tomcat.TomcatWebServer - Tomcat started on port(s): 9659 (http) with context path ''
2018-08-07 15:24:24,910 [main] INFO  com.zealot.StartUp - Started StartUp in 4.575 seconds (JVM running for 5.262)
2018-08-07 15:24:25,973 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Successfully joined group with generation 12
2018-08-07 15:24:25,976 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Successfully joined group with generation 12
2018-08-07 15:24:25,976 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Successfully joined group with generation 12
2018-08-07 15:24:25,977 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Successfully joined group with generation 12
2018-08-07 15:24:25,978 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-8, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 15:24:25,978 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Successfully joined group with generation 12
2018-08-07 15:24:25,978 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-9, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 15:24:25,978 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=flumetest] Setting newly assigned partitions [flume.log.test-4]
2018-08-07 15:24:25,978 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Successfully joined group with generation 12
2018-08-07 15:24:25,979 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-7, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 15:24:25,979 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-1, groupId=flumetest] Setting newly assigned partitions [flume.log.test-1]
2018-08-07 15:24:25,979 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Successfully joined group with generation 12
2018-08-07 15:24:25,979 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Successfully joined group with generation 12
2018-08-07 15:24:25,979 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Successfully joined group with generation 12
2018-08-07 15:24:25,979 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Successfully joined group with generation 12
2018-08-07 15:24:25,979 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-3, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 15:24:25,980 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-4, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 15:24:25,980 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-6, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 15:24:25,980 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-5, groupId=flumetest] Setting newly assigned partitions []
2018-08-07 15:24:25,980 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-10, groupId=flumetest] Setting newly assigned partitions [flume.log.test-2]
2018-08-07 15:24:25,981 [org.springframework.kafka.KafkaListenerEndpointContainer#0-7-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 15:24:25,981 [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 15:24:25,981 [org.springframework.kafka.KafkaListenerEndpointContainer#0-6-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 15:24:25,981 [org.springframework.kafka.KafkaListenerEndpointContainer#0-5-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 15:24:25,981 [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 15:24:25,982 [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 15:24:25,982 [org.springframework.kafka.KafkaListenerEndpointContainer#0-8-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: []
2018-08-07 15:24:25,986 [org.springframework.kafka.KafkaListenerEndpointContainer#0-9-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [flume.log.test-2]
2018-08-07 15:24:25,986 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [flume.log.test-1]
2018-08-07 15:24:25,987 [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] INFO  org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [flume.log.test-4]
